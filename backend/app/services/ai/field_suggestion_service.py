"""AI í•„ë“œ ì¶”ì²œ ì„œë¹„ìŠ¤"""
import json
import logging
from typing import Optional, Literal
from fastapi import HTTPException

from langchain_openai import ChatOpenAI
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import SystemMessage, HumanMessage

from backend.app.core.config import settings
from backend.app.schemas import FieldSuggestion
from .settings import get_text_model

logger = logging.getLogger(__name__)

SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ì»¬ë ‰ì…˜ ê´€ë¦¬ ì‹œìŠ¤í…œì˜ ë©”íƒ€ë°ì´í„° í•„ë“œ ì„¤ê³„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì‚¬ìš©ìê°€ ì»¬ë ‰ì…˜ ì´ë¦„ì„ ì œê³µí•˜ë©´, í•´ë‹¹ ì»¬ë ‰ì…˜ì— ì í•©í•œ ë©”íƒ€ë°ì´í„° í•„ë“œë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”.

**ì¤‘ìš” ê·œì¹™:**
1. keyëŠ” ì˜ë¬¸ ì†Œë¬¸ìì™€ ì–¸ë”ìŠ¤ì½”ì–´ë§Œ ì‚¬ìš© (snake_case)
2. labelì€ í•œêµ­ì–´ë¡œ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì§ˆ ì´ë¦„
3. typeì€ ë‹¤ìŒ ì¤‘ í•˜ë‚˜: text, textarea, number, date, select
4. select íƒ€ì…ì¼ ê²½ìš° options ë°°ì—´ í•„ìˆ˜
5. placeholderëŠ” ì…ë ¥ ì˜ˆì‹œë¥¼ ì œê³µ
6. ì¼ë°˜ì ìœ¼ë¡œ 5-15ê°œ í•„ë“œ ì¶”ì²œ
7. ê¸°ë³¸ í•„ë“œ: description(ì„¤ëª…), image_url(ì´ë¯¸ì§€), purchase_date(êµ¬ë§¤ì¼), purchase_price(êµ¬ë§¤ê°€ê²©), location(ë³´ê´€ìœ„ì¹˜), notes(ë©”ëª¨) í¬í•¨

**í•„ë“œ íƒ€ì… ê°€ì´ë“œ:**
- text: ì§§ì€ í…ìŠ¤íŠ¸ (ì´ë¦„, ì œëª©, ISBN ë“±)
- textarea: ê¸´ í…ìŠ¤íŠ¸ (ì„¤ëª…, ë©”ëª¨ ë“±)
- number: ìˆ«ì (ê°€ê²©, í˜ì´ì§€ ìˆ˜, ì¸ì› ë“±)
- date: ë‚ ì§œ (êµ¬ë§¤ì¼, ì¶œíŒì¼ ë“±)
- select: ì„ íƒ ì˜µì…˜ (ì¹´í…Œê³ ë¦¬, ì¥ë¥´, ìƒíƒœ ë“±)

ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{
  "fields": [
    {
      "key": "artist",
      "label": "ì•„í‹°ìŠ¤íŠ¸",
      "type": "text",
      "required": false,
      "placeholder": "ì˜ˆ: The Beatles"
    }
  ]
}
"""


def create_llm(provider: str, model_id: str = None):
    """LLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    if provider == "openai":
        if not settings.OPENAI_API_KEY:
            raise HTTPException(status_code=400, detail="OpenAI API key not configured")

        # ëª¨ë¸ IDê°€ ì§€ì •ë˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
        if not model_id:
            model_id = "gpt-4o-mini"

        return ChatOpenAI(
            model=model_id,
            api_key=settings.OPENAI_API_KEY,
            temperature=0.7,
        )
    elif provider == "gemini":
        if not settings.GEMINI_API_KEY:
            raise HTTPException(status_code=400, detail="Gemini API key not configured")

        # ëª¨ë¸ IDê°€ ì§€ì •ë˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
        if not model_id:
            model_id = "gemini-2.5-flash"

        return ChatGoogleGenerativeAI(
            model=model_id,
            google_api_key=settings.GEMINI_API_KEY,
            temperature=0.7,
        )
    else:
        raise HTTPException(status_code=400, detail="Unsupported provider")


async def suggest_fields(
    collection_name: str,
    description: Optional[str] = None,
    provider: Optional[Literal["openai", "gemini"]] = None,
    model_id: Optional[str] = None
) -> tuple[list[FieldSuggestion], str]:
    """AI ê¸°ë°˜ ì»¬ë ‰ì…˜ í•„ë“œ ì¶”ì²œ

    Returns:
        tuple[list[FieldSuggestion], str]: (í•„ë“œ ëª©ë¡, provider)
    """
    try:
        # providerì™€ model_id ê²°ì •
        if not provider:
            text_model = get_text_model()
            if text_model:
                provider = text_model["provider"]
                model_id = text_model["model_id"]
                logger.info(f"ğŸ“ ì„¤ì •ëœ ëª¨ë¸ ì‚¬ìš©: {provider}/{model_id}")
            else:
                # ëª¨ë¸ ì„¤ì •ì´ ì—†ìœ¼ë©´ ì—ëŸ¬ ë°œìƒ
                raise HTTPException(
                    status_code=400,
                    detail="AI ëª¨ë¸ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê´€ë¦¬ì í˜ì´ì§€ì—ì„œ AI ëª¨ë¸ì„ ë¨¼ì € ì„¤ì •í•´ì£¼ì„¸ìš”."
                )

        # LLM ìƒì„±
        llm = create_llm(provider, model_id)

        # ì‚¬ìš©ì ë©”ì‹œì§€ êµ¬ì„±
        user_message = f"ì»¬ë ‰ì…˜ ì´ë¦„: {collection_name}"
        if description:
            user_message += f"\nì„¤ëª…: {description}"

        # LangChain ë©”ì‹œì§€ ìƒì„±
        messages = [
            SystemMessage(content=SYSTEM_PROMPT),
            HumanMessage(content=user_message)
        ]

        # LLM í˜¸ì¶œ
        response = await llm.ainvoke(messages)

        # JSON íŒŒì‹±
        try:
            # ì½”ë“œ ë¸”ë¡ ì œê±°
            content = response.content.strip()
            if content.startswith("```json"):
                content = content[7:]
            if content.startswith("```"):
                content = content[3:]
            if content.endswith("```"):
                content = content[:-3]
            content = content.strip()

            result = json.loads(content)

            if "fields" not in result:
                raise ValueError("Invalid response format: missing 'fields' key")

            fields = [FieldSuggestion(**field) for field in result["fields"]]
            return fields, provider

        except json.JSONDecodeError as e:
            raise HTTPException(
                status_code=500,
                detail=f"Failed to parse AI response: {str(e)}\nResponse: {response.content[:200]}"
            )
        except Exception as e:
            raise HTTPException(
                status_code=500,
                detail=f"Failed to process AI response: {str(e)}"
            )

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"AI request failed: {str(e)}"
        )


async def translate_slug(name: str) -> str:
    """ì»¬ë ‰ì…˜ ì´ë¦„ì„ ì˜ë¬¸ slugë¡œ ë²ˆì—­

    Args:
        name: ì»¬ë ‰ì…˜ ì´ë¦„ (í•œê¸€ ê°€ëŠ¥)

    Returns:
        str: URL-safeí•œ ì˜ë¬¸ slug
    """
    import re

    try:
        # ì„¤ì •ëœ ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
        text_model_config = get_text_model()

        if text_model_config:
            provider = text_model_config["provider"]
            model_id = text_model_config["model_id"]
            logger.info(f"ğŸ“ Slug ë²ˆì—­ - ì„¤ì •ëœ ëª¨ë¸ ì‚¬ìš©: {provider}/{model_id}")
        else:
            # ëª¨ë¸ ì„¤ì •ì´ ì—†ìœ¼ë©´ ì—ëŸ¬ ë°œìƒ
            raise HTTPException(
                status_code=400,
                detail="AI ëª¨ë¸ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê´€ë¦¬ì í˜ì´ì§€ì—ì„œ AI ëª¨ë¸ì„ ë¨¼ì € ì„¤ì •í•´ì£¼ì„¸ìš”."
            )

        # LLM ìƒì„± (temperature=0 for consistent results)
        if provider == "openai":
            if not settings.OPENAI_API_KEY:
                raise HTTPException(status_code=400, detail="OpenAI API key not configured")
            llm = ChatOpenAI(model=model_id, api_key=settings.OPENAI_API_KEY, temperature=0)
        else:  # gemini
            if not settings.GEMINI_API_KEY:
                raise HTTPException(status_code=400, detail="Gemini API key not configured")
            llm = ChatGoogleGenerativeAI(model=model_id, google_api_key=settings.GEMINI_API_KEY, temperature=0)

        # í”„ë¡¬í”„íŠ¸
        prompt = f"""ë‹¤ìŒ ì»¬ë ‰ì…˜ ì´ë¦„ì„ URL-safeí•œ ì˜ë¬¸ slugë¡œ ë²ˆì—­í•˜ì„¸ìš”.

ê·œì¹™:
- ì†Œë¬¸ìë§Œ ì‚¬ìš©
- ê³µë°±ì€ í•˜ì´í”ˆ(-)ìœ¼ë¡œ
- íŠ¹ìˆ˜ë¬¸ì ì œê±°
- ì˜ë¯¸ë¥¼ ìµœëŒ€í•œ ìœ ì§€í•˜ë˜ ê°„ê²°í•˜ê²Œ
- í•œ ë‹¨ì–´ë¡œ í‘œí˜„ ê°€ëŠ¥í•˜ë©´ í•œ ë‹¨ì–´ë¡œ

ì»¬ë ‰ì…˜ ì´ë¦„: {name}

ì‘ë‹µì€ slugë§Œ ë°˜í™˜í•˜ì„¸ìš” (ì˜ˆ: manga, board-games, lego)"""

        # AI í˜¸ì¶œ
        response = await llm.ainvoke([HumanMessage(content=prompt)])
        slug = response.content.strip().lower()

        # ì•ˆì „ì„± ê²€ì¦ - ì˜ë¬¸, ìˆ«ì, í•˜ì´í”ˆë§Œ í—ˆìš©
        slug = re.sub(r'[^a-z0-9-]', '', slug)

        if not slug:
            # ë²ˆì—­ ì‹¤íŒ¨ ì‹œ fallback: ëœë¤ í•´ì‹œ
            import hashlib
            slug_hash = hashlib.md5(name.encode('utf-8')).hexdigest()[:8]
            slug = f"collection-{slug_hash}"
            logger.warning(f"âš ï¸ Slug ë²ˆì—­ ì‹¤íŒ¨, fallback ì‚¬ìš©: {slug}")

        logger.info(f"âœ… Slug ë²ˆì—­ ì™„ë£Œ: {name} -> {slug}")
        return slug

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Slug ë²ˆì—­ ì‹¤íŒ¨: {str(e)}")
        # Fallback: ëœë¤ í•´ì‹œ
        import hashlib
        slug_hash = hashlib.md5(name.encode('utf-8')).hexdigest()[:8]
        return f"collection-{slug_hash}"


